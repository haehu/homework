{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e231b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "print(\"슝=3\")\n",
    "#기본적으로 필요한 라이브러리 임폴트 하고 이번에 자료가 csv형태로 주어졌는데 어떻게 되어있는지 표 형태로 보기 위해서 판다스 pd 임폴트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "622028c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fb62c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab8307b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e337c668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "568918ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1d229e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b783bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "862140b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3999be26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93e4c140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('~/aiffel/transformer_chatbot/data/ChatbotData.csv')#데이터를 pd로 열어 표 형태로 보았다. Q, A, laber로 이루어져 있었다.\n",
    "data.head() #우리에게 중요한건 Q와 A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "107e72fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "458b9b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q        0\n",
       "A        0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()#결측치를 찾아 보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f89d42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop_duplicates()#결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56269bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # (ㄱ-ㅣ, 가-힣, a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  sentence = re.sub(r\"[^ㄱ-ㅣ가-힣,a-zA-Z?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d708102d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "q1=data[\"Q\"].map(lambda x: preprocess_sentence(x)) # 전처리함수 적용 map함수에 람다 함수를 사용하여 전처리를 하여 저장.\n",
    "a1=data[\"A\"].map(lambda x: preprocess_sentence(x)) \n",
    "print('전체 샘플 수 :', len(q1))\n",
    "print('전체 샘플 수 :', len(a1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1a06a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(seq):#RANKS NL의 한국어 stop words를 참조 불용어를 제거를 위해 리스트를 만듬 \n",
    "    stopwords=['아', '휴',\"휴우\", '아이구', '아이쿠', '아이고', '어', '나', '우리', \n",
    "               '저희', '따라', '의해', '을', '를', '에', '의', '가', '으로', \n",
    "               '로', '에게', '뿐이다', '의거하여', '근거하여', '입각하여', '기준으로', \n",
    "               '예하면', '예를 들면', '예를 들자면', '저', '소인', '소생', '저희', \n",
    "               '지말고', '하지마', '하지마라', '다른', '물론', '또한', '그리고', '비길수 없다',\n",
    "               '해서는 안된다', '뿐만 아니라', '만이 아니다', '만은 아니다', '막론하고', '관계없이', \n",
    "               '그치지 않다', '그러나', '그런데', '하지만', '든간에', '논하지 않다', '따지지 않다', \n",
    "               '설사', '비록', '더라도', '아니면', '만 못하다', '하는 편이 낫다', '불문하고', '향하여', \n",
    "               '향해서', '향하다', '쪽으로', '틈타', '이용하여', '타다', '오르다', '제외하고', '이 외에', \n",
    "               '이 밖에', '하여야', '비로소', '한다면 몰라도', '외에도', '이곳', '여기', '부터', \n",
    "               '기점으로', '따라서', '할 생각이다', '하려고하다', '이리하여', '그리하여', \n",
    "               '그렇게 함으로써', '하지만', '일때', '할때', '앞에서', '중에서', '보는데서', '으로써', \n",
    "               '로써', '까지', '해야한다', '일것이다', '반드시', '할줄알다', '할수있다', '할수있어', \n",
    "               '임에 틀림없다', '한다면', '등', '등등', '제', '겨우', '단지', '다만', '할뿐', '딩동', \n",
    "               '댕그', '대해서', '대하여', '대하면', '훨씬', '얼마나', '얼마만큼', '얼마큼', '남짓', \n",
    "               '여', '얼마간', '약간', '다소', '좀', '조금', '다수', '몇', '얼마', '지만', '하물며', \n",
    "               '또한', '그러나', '그렇지만', '하지만', '이외에도', '대해 말하자면', '뿐이다', '다음에', \n",
    "               '반대로', '반대로 말하자면', '이와 반대로', '바꾸어서 말하면', '바꾸어서 한다면', '만약', \n",
    "               '그렇지않으면', '까악', '툭', '딱', '삐걱거리다', '보드득', '비걱거리다', '꽈당', '응당', \n",
    "               '해야한다', '에 가서', '각', '각각', '여러분', '각종', '각자', '제각기', '하도록하다', \n",
    "               '와', '과', '그러므로', '그래서', '고로', '한 까닭에', '하기 때문에', '거니와', '이지만', \n",
    "               '대하여', '관하여', '관한', '과연', '실로', '아니나다를가', '생각한대로', '진짜로', '한적이있다', \n",
    "               '하곤하였다', '하', '하하', '허허', '아하', '거바', '와', '오', '왜', '어째서', '무엇때문에', '어찌', '하겠는가', \n",
    "               '무슨', '어디', '어느곳', '더군다나', '하물며', '더욱이는', '어느때', '언제', '야', '이봐', '어이', '여보시오', \n",
    "               '흐흐', '흥', '휴', '헉헉', '헐떡헐떡', '영차', '여차', '어기여차', '끙끙', '아야', '앗', '아야', '콸콸', '졸졸', \n",
    "               '좍좍', '뚝뚝', '주룩주룩', '솨', '우르르', '그래도', '또', '그리고', '바꾸어말하면', '바꾸어말하자면', '혹은', \n",
    "               '혹시', '답다', '및', '그에 따르는', '때가 되어', '즉', '지든지', '설령', '가령', '하더라도', '할지라도', '일지라도', \n",
    "               '지든지', '몇', '거의', '하마터면', '인젠', '이젠', '된바에야', '된이상', '만큼','어찌됏든', '그위에', '게다가', \n",
    "               '점에서 보아', '비추어 보아', '고려하면', '하게될것이다', '일것이다', '비교적', '좀', '보다더', '비하면', '시키다', \n",
    "               '하게하다', '할만하다', '의해서', '연이서', '이어서', '잇따라', '뒤따라', '뒤이어', '결국', '의지하여', '기대여',\n",
    "               '통하여', '자마자', '더욱더', '불구하고', '얼마든지', '마음대로', '주저하지 않고', '곧', '즉시', '바로', '당장', \n",
    "               '하자마자', '밖에 안된다', '하면된다', '그래', '그렇지', '요컨대', '다시 말하자면', '바꿔 말하면', '즉', '구체적으로',\n",
    "               '말하자면', '시작하여', '시초에', '이상', '허', '헉', '허걱', '바와같이', '해도좋다', '해도된다', '게다가', '더구나',\n",
    "               '하물며', '와르르', '팍', '퍽', '펄렁', '동안', '이래', '하고있었다', '이었다', '에서', '로부터', '까지', '예하면', \n",
    "               '했어요', '해요', '함께', '같이', '더불어', '마저', '마저도', '양자', '모두', '습니다', '가까스로', '하려고하다', '즈음하여', '다른', '다른 방면으로', '해봐요', '습니까', '했어요', '말할것도 없고', '무릎쓰고', '개의치않고', '하는것만 못하다', '하는것이 낫다', '매', '매번', '들', '모', '어느것', '어느', '로써', '갖고말하자면', '어디', '어느쪽', '어느것', '어느해', '어느 년도', '라 해도', '언젠가', '어떤것', '어느것', '저기', '저쪽', '저것', '그때', '그럼', '그러면', '요만한걸', '그래', '그때', '저것만큼', '그저', '이르기까지', '할 줄 안다', '할 힘이 있다', '너', '너희', '당신', '어찌', '설마', '차라리', '할지언정', '할지라도', '할망정', '할지언정', '구토하다', '게우다', '토하다', '메쓰겁다', '옆사람', '퉤', '쳇', '의거하여', '근거하여', '의해', '따라', '힘입어', '그', '다음', '버금', '두번째로', '기타', '첫번째로', '나머지는', '그중에서', '견지에서', '형식으로 쓰여', '입장에서', '위해서', '단지', '의해되다', '하도록시키다', '뿐만아니라', '반대로', '전후', '전자', '앞의것', '잠시', '잠깐', '하면서', '그렇지만', '다음에', '그러한즉', '그런즉', '남들', '아무거나', '어찌하든지', '같다', '비슷하다', '예컨대', '이럴정도로', '어떻게', '만약', '만일', '위에서 서술한바와같이', '인 듯하다', '하지 않는다면', '만약에', '무엇', '무슨', '어느', '어떤', '아래윗', '조차', '한데', '그럼에도 불구하고', '여전히', '심지어', '까지도', '조차도', '하지 않도록', '않기 위하여', '때', '시각', '무렵', '시간', '동안', '어때', '어떠한', '하여금', '네', '예', '우선', '누구', '누가 알겠는가', '아무도', '줄은모른다', '줄은 몰랏다', '하는 김에', '겸사겸사', '하는바', '그런 까닭에', '한 이유는', '그러니', '그러니까', '때문에', '그', '너희', '그들', '너희들', '타인', '것', '것들', '너', '위하여', '공동으로', '동시에', '하기 위하여', '어찌하여', '무엇때문에', '붕붕', '윙윙', '나', '우리', '엉엉', '휘익', '윙윙', '오호', '아하', '어쨋든', '만 못하다\\t하기보다는', '차라리', '하는 편이 낫다', '흐흐', '놀라다', '상대적으로 말하자면', '마치', '아니라면', '쉿', '그렇지 않으면', '그렇지 않다면', '안 그러면', '아니었다면', '하든지', '아니면', '이라면', '좋아', '알았어', '하는것도', '그만이다', '어쩔수 없다', '하나', '일', '일반적으로', '일단', '한켠으로는', '오자마자', '이렇게되면', '이와같다면', '전부', '한마디', '한항목', '근거로', '하기에', '아울러', '하지 않도록', '않기 위해서', '이르기까지', '이 되다', '로 인하여', '까닭으로', '이유만으로', '이로 인하여', '그래서', '이 때문에', '그러므로', '그런 까닭에', '알 수 있다', '결론을 낼 수 있다', '으로 인하여', '있다', '어떤것', '관계가 있다', '관련이 있다', '연관되다', '어떤것들', '에 대해', '이리하여', '그리하여', '여부', '하기보다는', '하느니', '하면 할수록', '운운', '이러이러하다', '하구나', '하도다', '다시말하면', '다음으로', '에 있다', '에 달려 있다', '우리', '우리들', '오히려', '하기는한데', '어떻게', '어떻해', '어찌됏어', '어때', '어째서', '본대로', '자', '이', '이쪽', '여기', '이것', '이번', '이렇게말하자면', '이런', '이러한', '이와 같은', '요만큼', '요만한 것', '얼마 안 되는 것', '이만큼', '이 정도의', '이렇게 많은 것', '이와 같다', '이때', '이렇구나', '것과 같이', '끼익', '삐걱', '따위', '와 같은 사람들', '부류의 사람들', '왜냐하면', '중의하나', '오직', '오로지', '에 한하다', '하기만 하면', '도착하다', '까지 미치다', '도달하다', '정도에 이르다', '할 지경이다', '결과에 이르다', '관해서는', '여러분', '하고 있다', '한 후', '혼자', '자기', '자기집', '자신', '우에 종합한것과같이', '총적으로 보면', '총적으로 말하면', '총적으로', '대로 하다', '으로서', '참', '그만이다', '할 따름이다', '쿵', '탕탕', '쾅쾅', '둥둥', '봐', '봐라', '아이야', '아니', '와아', '응', '아이', '참나', '년', '월', '일', '령', '영', '일', '이', '삼', '사', '오', '육', '륙', '칠', '팔', '구', '이천육', '이천칠', '이천팔', '이천구', '하나', '둘', '셋', '넷', '다섯', '여섯', '일곱', '여덟', '아홉', '령', '영']\n",
    "    for i in seq:\n",
    "        if i in stopwords:\n",
    "            seq.pop(seq.index(i))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "435507e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㄱㄱ\n"
     ]
    }
   ],
   "source": [
    "#불용어는 단어 단위, 각 문장을 띄어쓰기 단위로 잘라 단어 형태로 만든다.\n",
    "q2=q1.map(lambda x: x.split(\" \")) \n",
    "a2=a1.map(lambda x: x.split(\" \"))\n",
    "print('ㄱㄱ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7d9615c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㄱㄱ\n"
     ]
    }
   ],
   "source": [
    "q3=q2.map(lambda x: remove_stopwords(x))#불용어 제거\n",
    "a3=a2.map(lambda x: remove_stopwords(x))\n",
    "print('ㄱㄱ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9be656b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㄱㄱ\n"
     ]
    }
   ],
   "source": [
    "q4 = [\" \".join(i) for i in q3]#불용어를 제거한 질문과 답변을 문장으로 만든다.\n",
    "a4 = [\" \".join(i) for i in a3]\n",
    "print('ㄱㄱ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db34a274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\n",
      "슝=3 \n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "print(\"살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\")\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성. (Tensorflow 2.3.0 이상) (클라우드는 2.4 입니다)\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(q4 + a4, target_vocab_size=2**13)\n",
    "print(\"슝=3 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b44b0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3 \n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "print(\"슝=3 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0caccd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f01357c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8077]\n",
      "END_TOKEN의 번호 : [8078]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1aeef4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8079\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbd5d8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문의 최소 길이 : 0\n",
      "질문의 최대 길이 : 16\n",
      "질문의 평균 길이 : 3.7198680537934536\n",
      "대답의 최소 길이 : 0\n",
      "대답의 최대 길이 : 22\n",
      "대답의 평균 길이 : 4.5480842425780255\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "q_len = [len(s.split()) for s in q4]\n",
    "a_len = [len(s.split()) for s in a4]\n",
    "\n",
    "print('질문의 최소 길이 : {}'.format(np.min(q_len)))\n",
    "print('질문의 최대 길이 : {}'.format(np.max(q_len)))\n",
    "print('질문의 평균 길이 : {}'.format(np.mean(q_len)))\n",
    "print('대답의 최소 길이 : {}'.format(np.min(a_len)))\n",
    "print('대답의 최대 길이 : {}'.format(np.max(a_len)))\n",
    "print('대답의 평균 길이 : {}'.format(np.mean(a_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(q_len)\n",
    "plt.title('Q')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(a_len)\n",
    "plt.title('A')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Q')\n",
    "plt.hist(q_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('A')\n",
    "plt.hist(a_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show() #이런형태로 질문과 답변이 부포하는것을 알았다. 가장 긴 22에 토큰들을 포함하여 최대길이를 24로 정하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8bb8132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 24\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c35f8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 17 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0764411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8079\n",
      "필터링 후의 질문 샘플 개수: 11819\n",
      "필터링 후의 답변 샘플 개수: 11819\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(q4, a4)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a0b2328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "#질문과 답변의 쌍을 tf.data.Dataset API의 입력으로 사용하여 파이프라인을 구성합니다. \n",
    "#이때, 교사 강요를 위해서 answers[:, :-1]를 디코더의 입력값, answers[:, 1:]를 디코더의 레이블로 사용\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dbceb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22745f6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3122432     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3649792     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8079)   2076303     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,848,527\n",
      "Trainable params: 8,848,527\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7790e24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3b6b400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):#커스텀 학습률 스케줄러를 통한 아담 옵티마이저를 사용\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0771f8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)#시각화 러닝 레이트에 커스텀 학습률이 잘 적용된 것을 확인\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95383232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)#손실 함수와 커스텀 된 학습률(learning rate)을 사용하여 모델을 컴파일\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "923890d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "185/185 [==============================] - 14s 41ms/step - loss: 2.4085 - accuracy: 0.0384\n",
      "Epoch 2/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 1.9466 - accuracy: 0.0837\n",
      "Epoch 3/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 1.6498 - accuracy: 0.0860\n",
      "Epoch 4/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 1.5254 - accuracy: 0.0912\n",
      "Epoch 5/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 1.4315 - accuracy: 0.0967\n",
      "Epoch 6/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 1.3333 - accuracy: 0.1038\n",
      "Epoch 7/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 1.2244 - accuracy: 0.1133\n",
      "Epoch 8/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 1.1036 - accuracy: 0.1263\n",
      "Epoch 9/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.9748 - accuracy: 0.1399\n",
      "Epoch 10/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.8379 - accuracy: 0.1555\n",
      "Epoch 11/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.7009 - accuracy: 0.1725\n",
      "Epoch 12/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.5680 - accuracy: 0.1906\n",
      "Epoch 13/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.4466 - accuracy: 0.2085\n",
      "Epoch 14/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.3398 - accuracy: 0.2250\n",
      "Epoch 15/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.2505 - accuracy: 0.2404\n",
      "Epoch 16/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.1803 - accuracy: 0.2534\n",
      "Epoch 17/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.1314 - accuracy: 0.2620\n",
      "Epoch 18/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.1021 - accuracy: 0.2674\n",
      "Epoch 19/60\n",
      "185/185 [==============================] - 8s 42ms/step - loss: 0.0843 - accuracy: 0.2702\n",
      "Epoch 20/60\n",
      "185/185 [==============================] - 8s 42ms/step - loss: 0.0767 - accuracy: 0.2712\n",
      "Epoch 21/60\n",
      "185/185 [==============================] - 8s 42ms/step - loss: 0.0712 - accuracy: 0.2723\n",
      "Epoch 22/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0687 - accuracy: 0.2722\n",
      "Epoch 23/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0609 - accuracy: 0.2742\n",
      "Epoch 24/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0538 - accuracy: 0.2756\n",
      "Epoch 25/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0471 - accuracy: 0.2774\n",
      "Epoch 26/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0434 - accuracy: 0.2786\n",
      "Epoch 27/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0381 - accuracy: 0.2797\n",
      "Epoch 28/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0352 - accuracy: 0.2806\n",
      "Epoch 29/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0316 - accuracy: 0.2815\n",
      "Epoch 30/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0297 - accuracy: 0.2819\n",
      "Epoch 31/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0267 - accuracy: 0.2827\n",
      "Epoch 32/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0255 - accuracy: 0.2829\n",
      "Epoch 33/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0234 - accuracy: 0.2834\n",
      "Epoch 34/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0215 - accuracy: 0.2839\n",
      "Epoch 35/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0198 - accuracy: 0.2844\n",
      "Epoch 36/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0194 - accuracy: 0.2844\n",
      "Epoch 37/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0184 - accuracy: 0.2848\n",
      "Epoch 38/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0176 - accuracy: 0.2850\n",
      "Epoch 39/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0166 - accuracy: 0.2851\n",
      "Epoch 40/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0154 - accuracy: 0.2854\n",
      "Epoch 41/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0151 - accuracy: 0.2856\n",
      "Epoch 42/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0143 - accuracy: 0.2858\n",
      "Epoch 43/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0143 - accuracy: 0.2858\n",
      "Epoch 44/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0137 - accuracy: 0.2859\n",
      "Epoch 45/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0127 - accuracy: 0.2861\n",
      "Epoch 46/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0118 - accuracy: 0.2862\n",
      "Epoch 47/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0121 - accuracy: 0.2863\n",
      "Epoch 48/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0113 - accuracy: 0.2864\n",
      "Epoch 49/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0106 - accuracy: 0.2866\n",
      "Epoch 50/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0112 - accuracy: 0.2865\n",
      "Epoch 51/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.2866\n",
      "Epoch 52/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0098 - accuracy: 0.2868\n",
      "Epoch 53/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.2868\n",
      "Epoch 54/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0095 - accuracy: 0.2868\n",
      "Epoch 55/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0092 - accuracy: 0.2868\n",
      "Epoch 56/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0090 - accuracy: 0.2869\n",
      "Epoch 57/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0085 - accuracy: 0.2870\n",
      "Epoch 58/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.2870\n",
      "Epoch 59/60\n",
      "185/185 [==============================] - 8s 41ms/step - loss: 0.0081 - accuracy: 0.2871\n",
      "Epoch 60/60\n",
      "185/185 [==============================] - 8s 42ms/step - loss: 0.0075 - accuracy: 0.2872\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 60#20회 epoch일때 8s 41ms/step - loss: 0.0756 - accuracy: 0.2716 거의 되지않아 epochs를 60늘리도록 하였다.\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)#60회를 돌렸는데 정확도는 올라갔지만 오버피팅이 되지 않았나 걱정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6647612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "855acc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77f7f5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 퇴근하고 싶다\n",
      "출력 : 몸과 마음이 쉬어야 할 같아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'몸과 마음이 쉬어야 할 같아요 .'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('퇴근하고 싶다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1ff5b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 시험을 망쳤어\n",
      "출력 : 컨디션 조절 하세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'컨디션 조절 하세요 .'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('시험을 망쳤어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92186759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 사랑하는 사람이 생겼어\n",
      "출력 : 축하해요 . 예쁜 사랑하길 바라요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'축하해요 . 예쁜 사랑하길 바라요 .'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('사랑하는 사람이 생겼어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f6b99e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 쉬고 싶다\n",
      "출력 : 내려 놓으세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'내려 놓으세요 .'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('쉬고 싶다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90cca2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 난 운동을 좋아해\n",
      "출력 : 원치 않으면 싫다고 말하세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'원치 않으면 싫다고 말하세요 .'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('난 운동을 좋아해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "deffc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 뭐 먹을까\n",
      "출력 : 맛있는 거 드세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'맛있는 거 드세요 .'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 뭐 먹을까')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b4807b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 책 읽기 지겨워\n",
      "출력 : 도서관 데이트나 서점 데이트 좋을 거 같아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'도서관 데이트나 서점 데이트 좋을 거 같아요 .'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('책 읽기 지겨워')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53298ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20회를 돌렸을때 보다는 좋아진거 같다. 하지만 60회나 돌렸는데 로스는 줄어드는 반면에 정확도는 0.28애서 계소 정체된것을 볼 수 있었다. 기본\n",
    "#적인 설계나 전처리 과정에서 오류가 있지 않았을까 생각한다.\n",
    "#내가 생각한 첫번쨰는 불용어를 너무 과하게 지웠나 생각했다. 데이터 크기가 그렇게 크지 않은데 논문에서 적용된 정도의 불용어를 제거하여 \n",
    "#내 데이터에 비해 너무 많이 제거하지 않았나 싶다.\n",
    "#2번째는 데이터의 부족도 중요한 요소가 되지 않았나 싶다. 노드의 2만보다도 부족한 1.2만 정도의 데이터로 한 것이라 결고가 좋지 않았나 추측해\n",
    "#본다. 그래도 epoch를 변화시켜 조그이라도 나은 결과들이 나와서 다행이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
